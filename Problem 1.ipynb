{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enverus- Predictive Analytics Intern Recruitment\n",
    "## Problem 1 - Scraper for website http://imaging.occeweb.com/imaging/OGProd.aspx\n",
    "## Candidate: Hang Gong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate browser\n",
    "url = 'https://imaging.occ.ok.gov/imaging/OGProd.aspx'\n",
    "browser = webdriver.Chrome(executable_path='C:/Users/gongh/chromedriver.exe')\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass value and serach form\n",
    "dropdown = Select(browser.find_element_by_name(\"txtIndex7\"))\n",
    "dropdown.select_by_value(\"300R\")\n",
    "search_button = browser.find_element_by_id(\"Button1\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get headers for the dataframe\n",
    "doc = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "docs = doc.select('tbody')\n",
    "\n",
    "Headers = []\n",
    "for i in range(1,6):\n",
    "    Headers.append(docs[0].select('td')[i].text.strip())\n",
    "\n",
    "#initiate the list for columns value    \n",
    "list_0 = []\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "list_3 = []\n",
    "list_4 = []\n",
    "list_5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for find the click to change the page\n",
    "def click(link):\n",
    "    return browser.find_element_by_xpath(link).click()\n",
    "\n",
    "# function for getting the appended list of the data \n",
    "def get_list(num):\n",
    "    \n",
    "    click('//*[@id=\"DataGrid1\"]/tbody/tr[1]/td/a[{}]'.format(num))\n",
    "    time.sleep(15)\n",
    "    \n",
    "    doc = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    docs = doc.select('tbody')\n",
    "    table = docs[0].select('tr')\n",
    "\n",
    "    for i in range(2,len(table)-1):\n",
    "        columns = table[i].select('td')\n",
    "        list_0.append(columns[0].select('a')[0]['href'])\n",
    "        list_1.append(columns[0].text)\n",
    "        list_2.append(columns[1].text)\n",
    "        list_3.append(columns[2].text)\n",
    "        list_4.append(columns[3].text)\n",
    "        list_5.append(columns[4].text)\n",
    "    return list_0,list_1,list_2,list_3,list_4,list_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to generate the .csv file\n",
    "def main():\n",
    "    \n",
    "\n",
    "    doc = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    docs = doc.select('tbody')\n",
    "    table = docs[0].select('tr')\n",
    "    for i in range(2,len(table)-1):\n",
    "        columns = table[i].select('td')\n",
    "        list_0.append(columns[0].select('a')[0]['href'])\n",
    "        list_1.append(columns[0].text)\n",
    "        list_2.append(columns[1].text)\n",
    "        list_3.append(columns[2].text)\n",
    "        list_4.append(columns[3].text)\n",
    "        list_5.append(columns[4].text)\n",
    "\n",
    "    for k in range(1,22):\n",
    "        if k == 1:\n",
    "            for j in range(1,11):\n",
    "                get_list(j)\n",
    "        else:\n",
    "            for m in range(2,12):\n",
    "                get_list(m)\n",
    "\n",
    "    #for 212 final page\n",
    "    get_list(10)\n",
    "    data = pd.DataFrame({'link':list_0,'ID':list_1,'Prod_Date':list_2,'Purchaser_#':list_3,'Effective_Date':list_4,'Form_#':list_5})\n",
    "    data.to_csv('C:/Users/gongh/Dropbox/My PC (LAPTOP-CPI6NMVM)/Desktop/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
